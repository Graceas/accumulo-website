<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Accumulo™</title>
    <description>The Apache Accumulo™ sorted, distributed key/value store is a robust, scalable, high performance data storage and retrieval system.
</description>
    <link>https://accumulo.apache.org/</link>
    <atom:link href="https://accumulo.apache.org/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 11 Sep 2019 15:34:41 -0400</pubDate>
    <lastBuildDate>Wed, 11 Sep 2019 15:34:41 -0400</lastBuildDate>
    <generator>Jekyll v3.8.6</generator>
    
    
      <item>
        <title>Using S3 as a data store for Accumulo</title>
        <description>&lt;p&gt;Accumulo can store its files in S3, however S3 does not support the needs of
write ahead logs and the Accumulo metadata table. One way to solve this problem
is to store the metadata table and write ahead logs in HDFS and everything else
in S3.  This post shows how to do that using Accumulo 2.0 and Hadoop 3.2.0.
Running on S3 requires a new feature in Accumulo 2.0, that volume choosers are
aware of write ahead logs.&lt;/p&gt;

&lt;h2 id=&quot;hadoop-setup&quot;&gt;Hadoop setup&lt;/h2&gt;

&lt;p&gt;At least the following settings should be added to Hadoop’s &lt;code class=&quot;highlighter-rouge&quot;&gt;core-site.xml&lt;/code&gt; file on each node in the cluster.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.s3a.access.key&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;KEY&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.s3a.secret.key&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;SECRET&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- without this setting Accumulo tservers would have problems when trying to open lots of files --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.s3a.connection.maximum&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;128&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See &lt;a href=&quot;https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#S3A&quot;&gt;S3A docs&lt;/a&gt;
for more S3A settings.  To get hadoop command to work with s3 set &lt;code class=&quot;highlighter-rouge&quot;&gt;export
HADOOP_OPTIONAL_TOOLS=&quot;hadoop-aws&quot;&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;hadoop-env.sh&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When trying to use Accumulo with Hadoop’s AWS jar &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-16080&quot;&gt;HADOOP-16080&lt;/a&gt; was
encountered.  The following instructions build a relocated hadoop-aws jar as a
work around.  After building the jar copy it to all nodes in the cluster.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /tmp/haws-reloc
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /tmp/haws-reloc
&lt;span class=&quot;c&quot;&gt;# get the Maven pom file that builds a relocated jar&lt;/span&gt;
wget https://gist.githubusercontent.com/keith-turner/f6dcbd33342732e42695d66509239983/raw/714cb801eb49084e0ceef5c6eb4027334fd51f87/pom.xml
mvn package &lt;span class=&quot;nt&quot;&gt;-Dhadoop&lt;/span&gt;.version&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&amp;lt;your hadoop version&amp;gt;
&lt;span class=&quot;c&quot;&gt;# the new jar will be in target&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;ls &lt;/span&gt;target/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;accumulo-setup&quot;&gt;Accumulo setup&lt;/h2&gt;

&lt;p&gt;For each node in the cluster, modify &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-env.sh&lt;/code&gt; to add S3 jars to the
classpath.  Your versions may differ depending on your Hadoop version,
following versions were included with Hadoop 3.2.0.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/*:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_CONF_DIR&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ZOOKEEPER_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/*:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/share/hadoop/client/*&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:/somedir/hadoop-aws-relocated.3.2.0.jar&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/share/hadoop/tools/lib/aws-java-sdk-bundle-1.11.375.jar&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# The following are dependencies needed by by the previous jars and are subject to change&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/share/hadoop/common/lib/jaxb-api-2.2.11.jar&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/share/hadoop/common/lib/commons-lang3-3.7jar&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;CLASSPATH
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Set the following in &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo.properties&lt;/code&gt; and then run &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo init&lt;/code&gt;, but don’t start Accumulo.&lt;/p&gt;

&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;py&quot;&gt;instance.volumes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hdfs://&amp;lt;name node&amp;gt;/accumulo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After running Accumulo init we need to configure storing write ahead logs in
HDFS.  Set the following in &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo.properties&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;py&quot;&gt;instance.volumes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hdfs://&amp;lt;name node&amp;gt;/accumulo,s3a://&amp;lt;bucket&amp;gt;/accumulo&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;general.volume.chooser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;org.apache.accumulo.server.fs.PreferredVolumeChooser&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;general.custom.volume.preferred.default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s3a://&amp;lt;bucket&amp;gt;/accumulo&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;general.custom.volume.preferred.logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hdfs://&amp;lt;namenode&amp;gt;/accumulo&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Run &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo init --add-volumes&lt;/code&gt; to initialize the S3 volume.  Doing this
in two steps avoids putting any Accumulo metadata files in S3 during init.
Copy &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo.properties&lt;/code&gt; to all nodes and start Accumulo.&lt;/p&gt;

&lt;p&gt;Individual tables can be configured to store their files in HDFS by setting the
table property &lt;code class=&quot;highlighter-rouge&quot;&gt;table.custom.volume.preferred&lt;/code&gt;.  This should be set for the
metadata table in case it splits using the following Accumulo shell command.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;config -t accumulo.metadata -s table.custom.volume.preferred=hdfs://&amp;lt;namenode&amp;gt;/accumulo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;accumulo-example&quot;&gt;Accumulo example&lt;/h2&gt;

&lt;p&gt;The following Accumulo shell session shows an example of writing data to S3 and
reading it back.  It also shows scanning the metadata table to verify the data
is stored in S3.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@muchos&amp;gt; createtable s3test
root@muchos s3test&amp;gt; insert r1 f1 q1 v1
root@muchos s3test&amp;gt; insert r1 f1 q2 v2
root@muchos s3test&amp;gt; flush -w
2019-09-10 19:39:04,695 [shell.Shell] INFO : Flush of table s3test  completed.
root@muchos s3test&amp;gt; scan 
r1 f1:q1 []    v1
r1 f1:q2 []    v2
root@muchos s3test&amp;gt; scan -t accumulo.metadata -c file
2&amp;lt; file:s3a://&amp;lt;bucket&amp;gt;/accumulo/tables/2/default_tablet/F000007b.rf []    234,2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These instructions were only tested a few times and may not result in a stable
system. I have &lt;a href=&quot;https://gist.github.com/keith-turner/149f35f218d10e13227461714012d7bf&quot;&gt;run&lt;/a&gt; a 24hr test with Accumulo and S3.&lt;/p&gt;

&lt;h2 id=&quot;is-s3guard-needed&quot;&gt;Is S3Guard needed?&lt;/h2&gt;

&lt;p&gt;I am not completely certain about this, but I don’t think S3Guard is needed for
regular Accumulo tables.  There are two reasons I think this is so.  First each
Accumulo user tablet stores its list of files in the metadata table using
absolute URIs.  This allows a tablet to have files on multiple DFS instances.
Therefore Accumulo never does a DFS list operation to get a tablets files, it
always uses whats in the metadata table.  Second, Accumulo gives each file a
unique name using a counter stored in Zookeeper and file names are never
reused.&lt;/p&gt;

&lt;p&gt;Things are sligthly different for Accumulo’s metadata.  User tablets store
their file list in the metadata table.  Metadata tablets store their file list
in the root table.  The root table stores its file list in DFS.  Therefore it
would be dangerous to place the root tablet in S3 w/o using S3Guard.  That is
why these instructions place Accumulo metadata in HDFS. &lt;strong&gt;Hopefully&lt;/strong&gt; this
configuration allows the system to be consistent w/o using S3Guard.&lt;/p&gt;

&lt;p&gt;When Accumulo 2.1.0 is released with the changes made by &lt;a href=&quot;https://github.com/apache/accumulo/issues/1313&quot;&gt;#1313 &lt;/a&gt; for issue
&lt;a href=&quot;https://github.com/apache/accumulo/issues/936&quot;&gt;#936 &lt;/a&gt;, it may be possible to store the metadata table in S3 w/o
S3Gaurd.  If this is the case then only the write ahead logs would need to be
stored in HDFS.&lt;/p&gt;

</description>
        <pubDate>Tue, 10 Sep 2019 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2019/09/10/accumulo-S3-notes.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2019/09/10/accumulo-S3-notes.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Top 10 Reasons to Upgrade</title>
        <description>&lt;p&gt;Accumulo 2.0 has been in development for quite some time now and is packed with new features, bug
fixes, performance improvements and redesigned components.  All of these changes bring challenges
when upgrading your production cluster so you may be wondering… why should I upgrade?&lt;/p&gt;

&lt;p&gt;My top 10 reasons to upgrade. For all changes see the &lt;a href=&quot;https://accumulo.apache.org/release/accumulo-2.0.0/&quot;&gt;release notes&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#summaries&quot;&gt;Summaries&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#new-bulk-import&quot;&gt;New Bulk Import&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#simplified-scripts-and-config&quot;&gt;Simplified Scripts and Config&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#new-monitor&quot;&gt;New Monitor&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#new-apis&quot;&gt;New APIs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#offline-creation&quot;&gt;Offline creation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#search-documentation&quot;&gt;Search Documentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#new-crypto&quot;&gt;On disk encryption&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#zstandard-compression&quot;&gt;ZStandard Compression&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#new-scan-executors&quot;&gt;New Scan Executors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summaries&quot;&gt;Summaries&lt;/h3&gt;

&lt;p&gt;This feature allows detailed stats about Tables to be written directly into Accumulo files (R-Files). 
Summaries can be used to make precise decisions about your data. Once configured, summaries become a 
part of your Tables, so they won’t impact ingest or query performance of your cluster.&lt;/p&gt;

&lt;p&gt;Here are some example use cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A compaction could automatically run if deletes compose more than 25% of the data&lt;/li&gt;
  &lt;li&gt;An admin could optimize compactions by configuring specific age off of data&lt;/li&gt;
  &lt;li&gt;An admin could analyze R-File summaries for better performance tuning of a cluster&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more info check out the &lt;a href=&quot;/docs/2.x//development/summaries&quot;&gt;summary docs for 2.0&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;new-bulk-import&quot;&gt;New Bulk Import&lt;/h3&gt;

&lt;p&gt;Bulk Ingest was completely redone for 2.0.  Previously, Bulk Ingest relied on expensive inspections of 
R-Files across multiple Tablet Servers. With enough data, an old Bulk Ingest operation could easily 
hold up simpler Table operations and critical compactions of files.&lt;/p&gt;

&lt;p&gt;The new Bulk Ingest gives the user control over the R-File inspection, allows for offline bulk
ingesting and provides performance &lt;a href=&quot;https://accumulo.apache.org/release/accumulo-2.0.0/#new-bulk-import-api&quot;&gt;improvements&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;simplified-scripts-and-config&quot;&gt;Simplified Scripts and Config&lt;/h2&gt;

&lt;p&gt;Many improvements were done to the scripts and configuration. See Mike’s description of the &lt;a href=&quot;https://accumulo.apache.org/blog/2016/11/16/simpler-scripts-and-config.html&quot;&gt;improvements.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;new-monitor&quot;&gt;New Monitor&lt;/h2&gt;

&lt;p&gt;The Monitor has been re-written using REST, Javascript and more modern Web Tech.  It is faster, 
cleaner and more maintainable than the previous version. Here is a screen shot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/accumulo-monitor-1.png&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;new-apis&quot;&gt;New APIs&lt;/h2&gt;

&lt;p&gt;Connecting to Accumulo is now easier with a single point of entry for clients. It can now be done with 
a fluent API, 2 imports and using minimal code:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.accumulo.core.client.Accumulo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.accumulo.core.client.AccumuloClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;AccumuloClient&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Accumulo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;newClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;instance&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;zk&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;user&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;pass&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// use the client&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;tableOperations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;newTable&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see the client is also closable, which gives developers more control over resources.
See the &lt;a href=&quot;https://static.javadoc.io/org.apache.accumulo/accumulo-core/2.0.0/org/apache/accumulo/core/client/Accumulo.html&quot;&gt;Accumulo entry point javadoc&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Key and Mutation have new fluent APIs, which now allow mixing of &lt;code class=&quot;highlighter-rouge&quot;&gt;String&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;byte[]&lt;/code&gt; types.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;Key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newKey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;foo&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;family&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bar&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;Mutation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Mutation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;row0017&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;at&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;family&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;001&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;qualifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;v99&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;at&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;family&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;002&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;qualifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;More examples for &lt;a href=&quot;https://github.com/apache/accumulo/blob/master/core/src/test/java/org/apache/accumulo/core/data/KeyBuilderTest.java&quot;&gt;Key&lt;/a&gt; and &lt;a href=&quot;https://static.javadoc.io/org.apache.accumulo/accumulo-core/2.0.0/org/apache/accumulo/core/data/Mutation.html#at()&quot;&gt;Mutation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;table-creation-options&quot;&gt;Table creation options&lt;/h2&gt;

&lt;p&gt;Tables can now be created with splits, which is much faster than creating a
table and then adding splits.  Tables can also be created in an offline state
now.  The new bulk import API supports offline tables.  This enables the
following method of getting a lot of data into a new table very quickly.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create offline table with splits&lt;/li&gt;
  &lt;li&gt;Bulk import into new offline table&lt;/li&gt;
  &lt;li&gt;Bring table online&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the javadoc for &lt;a href=&quot;https://static.javadoc.io/org.apache.accumulo/accumulo-core/2.0.0/org/apache/accumulo/core/client/admin/NewTableConfiguration.html&quot;&gt;NewTableConfiguration&lt;/a&gt; and search for methods introduced in 2.0.0 for more information.&lt;/p&gt;

&lt;h2 id=&quot;search-documentation&quot;&gt;Search Documentation&lt;/h2&gt;

&lt;p&gt;New ability to quickly search documentation on the website. The user manual was completely redone 
for 2.0. Check it out &lt;a href=&quot;/docs/2.x//getting-started/quickstart&quot;&gt;here&lt;/a&gt;. Users can now quickly &lt;a href=&quot;https://accumulo.apache.org/search/&quot;&gt;search&lt;/a&gt; the website across all 2.x documentation.&lt;/p&gt;

&lt;h2 id=&quot;new-crypto&quot;&gt;New Crypto&lt;/h2&gt;

&lt;p&gt;On disk encryption was redone to be more secure and flexible. For an in depth description of how Accumulo 
does on disk encryption, see the &lt;a href=&quot;/docs/2.x//security/on-disk-encryption&quot;&gt;user manual&lt;/a&gt;.  NOTE: This is currently an experimental feature.
An experimental feature is considered a work in progress or incomplete and could change.&lt;/p&gt;

&lt;h2 id=&quot;zstandard-compression&quot;&gt;Zstandard compression&lt;/h2&gt;

&lt;p&gt;Support for Zstandard compression was added in 2.0.  It has been measured to perform better than 
gzip (better compression ratio and speed) and snappy (better compression ratio). Checkout Facebook’s &lt;a href=&quot;https://facebook.github.io/zstd/&quot;&gt;github&lt;/a&gt; for Zstandard and
the &lt;a href=&quot;/docs/2.x//configuration/server-properties&quot;&gt;table.file.compress.type&lt;/a&gt; property for configuring Accumulo.&lt;/p&gt;

&lt;h2 id=&quot;new-scan-executors&quot;&gt;New Scan Executors&lt;/h2&gt;

&lt;p&gt;Users now have more control over scans with the new scan executors.  Tables can be configured to utilize these 
powerful new mechanisms using just a few properties, giving user control over things like scan prioritization and 
better cluster resource utilization.&lt;/p&gt;

&lt;p&gt;For example, a cluster has a bunch of long running scans and one really fast scan.  The long running scans will eat up 
a majority of the server resources causing the one really fast scan to be delayed.  Scan executors allow an admin 
to configure the cluster in a way that allows the one fast scan to be prioritized and not have to wait.&lt;/p&gt;

&lt;p&gt;Checkout some examples in the &lt;a href=&quot;/docs/2.x//administration/scan-executors&quot;&gt;user guide&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Mon, 12 Aug 2019 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2019/08/12/why-upgrade.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2019/08/12/why-upgrade.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 2.0.0</title>
        <description>&lt;p&gt;Apache Accumulo 2.0.0 contains significant changes from 1.9 and earlier
versions. It is the first major release since adopting &lt;a href=&quot;https://semver.org/spec/v2.0.0.html&quot;&gt;semver&lt;/a&gt; and is the
culmination of more than 3 years worth of work by more than 40 contributors
from the Accumulo community. The following release notes highlight some of the
changes. If anything is missing from this list, please &lt;a href=&quot;/contact-us&quot;&gt;contact&lt;/a&gt; the developers
to have it included.&lt;/p&gt;

&lt;h2 id=&quot;notable-changes&quot;&gt;Notable Changes&lt;/h2&gt;

&lt;h3 id=&quot;new-api-for-creating-connections-to-accumulo&quot;&gt;New API for creating connections to Accumulo&lt;/h3&gt;

&lt;p&gt;A fluent API for creating Accumulo clients was introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4784&quot;&gt;ACCUMULO-4784&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/accumulo/issues/634&quot;&gt;#634&lt;/a&gt;.
The &lt;code class=&quot;highlighter-rouge&quot;&gt;Connector&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ZooKeeperInstance&lt;/code&gt; objects have been deprecated and replaced by
&lt;code class=&quot;highlighter-rouge&quot;&gt;AccumuloClient&lt;/code&gt; which is created from the &lt;code class=&quot;highlighter-rouge&quot;&gt;Accumulo&lt;/code&gt; entry point. The new API also deprecates
&lt;code class=&quot;highlighter-rouge&quot;&gt;ClientConfiguration&lt;/code&gt; and introduces its own properties file called &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-client.properties&lt;/code&gt;
that ships with the Accumulo tarball. The new API has the following benefits over the old API:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;All connection information can be specifed in properties file to create the client. This was not
possible with old API.&lt;/li&gt;
  &lt;li&gt;The new API does not require &lt;code class=&quot;highlighter-rouge&quot;&gt;ZooKeeperInstance&lt;/code&gt; to be created first before creating a client.&lt;/li&gt;
  &lt;li&gt;The new client is closeable and does not rely on shared static resource management&lt;/li&gt;
  &lt;li&gt;Clients can be created using a new Java builder, &lt;code class=&quot;highlighter-rouge&quot;&gt;Properties&lt;/code&gt; object, or &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-client.properties&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Clients can now be created with default settings for &lt;code class=&quot;highlighter-rouge&quot;&gt;BatchWriter&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Scanner&lt;/code&gt;, etc.&lt;/li&gt;
  &lt;li&gt;Create scanners with default authorizations. &lt;a href=&quot;https://github.com/apache/accumulo/issues/744&quot;&gt;#744 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the &lt;a href=&quot;/docs/2.x/getting-started/clients&quot;&gt;client documentation&lt;/a&gt; for more information on how to use the new API.&lt;/p&gt;

&lt;h3 id=&quot;hadoop-3-java-8--11&quot;&gt;Hadoop 3 Java 8 &amp;amp; 11.&lt;/h3&gt;

&lt;p&gt;Accumulo 2.x expects at least Java 8 and Hadoop 3.  It is built against Java 8
and Hadoop 3 and the binary tarball is targeted to work with a Java 8 and
Hadoop 3 system.  See &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4826&quot;&gt;ACCUMULO-4826 &lt;/a&gt;,  &lt;a href=&quot;https://github.com/apache/accumulo/issues/531&quot;&gt;#531 &lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4299&quot;&gt;ACCUMULO-4299 &lt;/a&gt;.  Running with Java 11 is also supported, but Java 11 is not
required.&lt;/p&gt;

&lt;h3 id=&quot;simplified-accumulo-scripts-and-configuration-files&quot;&gt;Simplified Accumulo scripts and configuration files&lt;/h3&gt;

&lt;p&gt;Accumulo’s scripts and configuration were refactored in &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4490&quot;&gt;ACCUMULO-4490&lt;/a&gt; to make Accumulo
easier to use. The number of scripts in the &lt;code class=&quot;highlighter-rouge&quot;&gt;bin&lt;/code&gt; directory of the Accumulo release tarball
has been reduced from 20 scripts to the four scripts below:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo&lt;/code&gt; - mostly left alone except for improved usage&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-service&lt;/code&gt; - manage Accumulo processes as services&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-cluster&lt;/code&gt; - manage Accumulo on cluster. Replaces &lt;code class=&quot;highlighter-rouge&quot;&gt;start-all.sh&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;stop-all.sh&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo-util&lt;/code&gt; - combines many utility scripts into one script.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Read &lt;a href=&quot;/blog/2016/11/16/simpler-scripts-and-config.html&quot;&gt;this blog post&lt;/a&gt; for more information on this change.&lt;/p&gt;

&lt;h3 id=&quot;new-bulk-import-api&quot;&gt;New Bulk Import API&lt;/h3&gt;

&lt;p&gt;A new bulk import API was added in 2.0 that has very different implementation.  This new API supports the following new functionality.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bulk import to an offline table.&lt;/li&gt;
  &lt;li&gt;Load plans that specify where files go in a table which avoids opening the
files for inspection.&lt;/li&gt;
  &lt;li&gt;Inspection of file on the client side. Inspection of all files is done
before the FATE operation starts.  This results in less namenode operations
and fail-fast for bad files (no longer need a fail directory).&lt;/li&gt;
  &lt;li&gt;A new improved algorithm to load files into tablets.  This new algorithm
scans the metadata table and makes asynchronous load calls to all tablets.
This queues load operations on all tablets at around the same time.  The
async RPC calls and beforehand inspection make the bulk load FATE operation
much shorter.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The shell command for doing bulk load supports the old and new API.  To use the
new API from the shell simply omit the failure directory argument.
For the API, use the &lt;a href=&quot;https://static.javadoc.io/org.apache.accumulo/accumulo-core/2.0.0/org/apache/accumulo/core/client/admin/TableOperations.html#importDirectory(java.lang.String)&quot;&gt;new fluent API&lt;/a&gt;.
See &lt;a href=&quot;https://github.com/apache/accumulo/issues/436&quot;&gt;#436 &lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/accumulo/issues/472&quot;&gt;#472 &lt;/a&gt;, and &lt;a href=&quot;https://github.com/apache/accumulo/issues/570&quot;&gt;#570 &lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;summaries&quot;&gt;Summaries&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/docs/2.x/development/summaries&quot;&gt;Summaries&lt;/a&gt; enables continually generating
statistics about a table with user defined functions.  This feature can inform
a user about what is in their table and be used by compaction strategies to
make decisions.  For example, using this feature it would be possible to
compact all tablets where deletes are more than 25% of the data. Another
example use case is optimizing filtering compactions by enabling smart
selection of files with pertinent data. Examples of filtering compactions are
age off and removal of non-compliant data.&lt;/p&gt;

&lt;h3 id=&quot;scan-executors&quot;&gt;Scan Executors&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/docs/2.x/administration/scan-executors&quot;&gt;Scan executors&lt;/a&gt; support prioritizing
and dedicating scan resources. Each executor has a configurable number of
threads and an optional custom prioritizer.  Tables can be configured in a
flexible way to dispatch scans to different executors.&lt;/p&gt;

&lt;h3 id=&quot;spi-package&quot;&gt;SPI package&lt;/h3&gt;

&lt;p&gt;All new pluggable components introduced in 2.0 were placed under a new SPI
package.  The SPI package is analyzed by &lt;a href=&quot;https://code.revelc.net/apilyzer-maven-plugin/&quot;&gt;Apilyzer&lt;/a&gt; at build time to ensure
plugins only use SPI and API types.  This prevents plugins from using internal
Accumulo types that are inherently unstable over time.  Plugins created before
2.0 do use internal types and are less stable.  The new pluggable interfaces
should be much more stable.&lt;/p&gt;

&lt;h3 id=&quot;official-accumulo-docker-image-was-created&quot;&gt;Official Accumulo docker image was created&lt;/h3&gt;

&lt;p&gt;An &lt;a href=&quot;https://github.com/apache/accumulo-docker&quot;&gt;official Accumulo docker images&lt;/a&gt; was created in &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4706&quot;&gt;ACCUMULO-4706&lt;/a&gt; to make
it easier for users to run Accumulo in Docker. To support running in Docker, a few changes were
made to Accumulo:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;--upload-accumulo-site&lt;/code&gt; option was added to &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo init&lt;/code&gt; to set properties in accumulo-site.xml
to Zookeeper during initialization.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;-o &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt;&lt;/code&gt; option was added to the &lt;code class=&quot;highlighter-rouge&quot;&gt;accumulo&lt;/code&gt; command to override configuration that could
not be set in Zookeeper.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;updated-and-improved-accumulo-documentation&quot;&gt;Updated and improved Accumulo documentation&lt;/h3&gt;

&lt;p&gt;Accumulo’s documentation has been refactored with the following improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Documentation source now lives in &lt;a href=&quot;https://github.com/apache/accumulo-website&quot;&gt;accumulo-website repo&lt;/a&gt; so changes
are now immediately viewable.&lt;/li&gt;
  &lt;li&gt;Improved navigation using a new sidebar&lt;/li&gt;
  &lt;li&gt;Better linking to Javadocs, between documentation pages, and to configuration properties.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Accumulo’s documentation was also reviewed and changes were made to improve accuracy and remove
out of date documentation.&lt;/p&gt;

&lt;h3 id=&quot;moved-accumulo-examples-to-its-own-repo&quot;&gt;Moved Accumulo Examples to its own repo&lt;/h3&gt;

&lt;p&gt;The Accumulo examples were moved out the accumulo repo to the &lt;a href=&quot;https://github.com/apache/accumulo-examples&quot;&gt;accumulo-examples repo&lt;/a&gt;
which has the following benefits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Accumulo examples are no longer released with Accumulo and can be continuously improved.&lt;/li&gt;
  &lt;li&gt;The Accumulo API version used by the examples can be updated right before Accumulo is released
to test for any changes to the API that break semver.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;simplified-accumulo-logging-configuration&quot;&gt;Simplified Accumulo logging configuration&lt;/h3&gt;

&lt;p&gt;The log4j configuration of Accumulo services was improved in &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4588&quot;&gt;ACCUMULO-4588&lt;/a&gt; with the following changes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Logging is now configured using standard log4j JVM property ‘log4j.configuration’ in accumulo-env.sh.&lt;/li&gt;
  &lt;li&gt;Tarball ships with fewer log4j config files (3 rather than 6) which are all log4j properties files.&lt;/li&gt;
  &lt;li&gt;Log4j XML can still be used by editing accumulo-env.sh&lt;/li&gt;
  &lt;li&gt;Removed auditLog.xml and added audit log configuration to log4j-service properties files&lt;/li&gt;
  &lt;li&gt;Accumulo conf/ directory no longer has an examples/ directory. Configuration files ship in conf/ and are
used by default.&lt;/li&gt;
  &lt;li&gt;Accumulo monitor by default will bind to 0.0.0.0 but will advertise hostname looked up in Java for log
forwarding&lt;/li&gt;
  &lt;li&gt;Switched to use full hostnames rather than short hostnames for logging&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;removed-comparison-of-value-with-byte-in-valueequals&quot;&gt;Removed comparison of Value with byte[] in Value.equals()&lt;/h3&gt;

&lt;p&gt;Replaced the ability to use &lt;code class=&quot;highlighter-rouge&quot;&gt;Value.equals(byte[])&lt;/code&gt; to check if the contents of a
&lt;code class=&quot;highlighter-rouge&quot;&gt;Value&lt;/code&gt; object was equal to a given byte array in &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4726&quot;&gt;ACCUMULO-4726&lt;/a&gt;. To perform
that check, you must now use the newly added &lt;code class=&quot;highlighter-rouge&quot;&gt;Value.contentEquals(byte[])&lt;/code&gt;
method. This corrects the behavior of the &lt;code class=&quot;highlighter-rouge&quot;&gt;equals&lt;/code&gt; method so that it conforms
to the API contract documented in the javadoc inherited from its superclass.
However, it will break any code that was relying on the undocumented and broken
behavior to compare &lt;code class=&quot;highlighter-rouge&quot;&gt;Value&lt;/code&gt; objects with byte arrays. Such comparisons will now
always return &lt;code class=&quot;highlighter-rouge&quot;&gt;false&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;, even if the contents are equal.&lt;/p&gt;

&lt;h3 id=&quot;other-notable-changes&quot;&gt;Other Notable Changes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-3652&quot;&gt;ACCUMULO-3652&lt;/a&gt; - Replaced string concatenation in log statements with slf4j
where applicable. Removed tserver TLevel logging class.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4449&quot;&gt;ACCUMULO-4449&lt;/a&gt; - Removed ‘slave’ terminology and replaced with ‘tserver’ in
most cases. The former ‘slaves’ config file is now named ‘tservers’. Added checks to
scripts to fail if ‘slaves’ file is present.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4808&quot;&gt;ACCUMULO-4808 &lt;/a&gt; - Can now create table with splits and offline.  Specifying splits
at table creation time can be much faster than adding splits after creation.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4463&quot;&gt;ACCUMULO-4463 &lt;/a&gt; - Caching is now pluggable.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4177&quot;&gt;ACCUMULO-4177 &lt;/a&gt; - New built in cache implementation based on TinyLFU.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4376&quot;&gt;ACCUMULO-4376 &lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4746&quot;&gt;ACCUMULO-4746 &lt;/a&gt; - Mutation and Key Fluent APIs allow easy mixing of types.  For example a family of type &lt;code class=&quot;highlighter-rouge&quot;&gt;String&lt;/code&gt; and qualifier of type &lt;code class=&quot;highlighter-rouge&quot;&gt;byte[]&lt;/code&gt; is much easier to write using this new API.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4771&quot;&gt;ACCUMULO-4771 &lt;/a&gt; - The Accumulo monitor was completely rewritten.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4732&quot;&gt;ACCUMULO-4732 &lt;/a&gt; - Specify iterators and locality groups at table creation time.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-4612&quot;&gt;ACCUMULO-4612 &lt;/a&gt; - Use percentages for memory related configuration.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ACCUMULO-1787&quot;&gt;ACCUMULO-1787 &lt;/a&gt; - Two tier compaction strategy.  Support compacting small files with snappy and large files with gzip.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/560&quot;&gt;#560 &lt;/a&gt; - Provide new Crypto interface &amp;amp; impl&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/536&quot;&gt;#536 &lt;/a&gt; - Removed mock Accumulo.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/438&quot;&gt;#438 &lt;/a&gt; - Added support for ZStandard compression&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/404&quot;&gt;#404 &lt;/a&gt; - Added basic Grafana dashboard example.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/1102&quot;&gt;#1102 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/1100&quot;&gt;#1100 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/1037&quot;&gt;#1037 &lt;/a&gt; - Removed lock contention in different areas.  These locks caused threads working unrelated task to impede each other.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/1033&quot;&gt;#1033 &lt;/a&gt; - Optimized the default compaction strategy.  In some cases the Accumulo would rewrite data O(N^2) times over repeated compactions.  With this change the amount of rewriting is always logarithmic.&lt;/li&gt;
  &lt;li&gt;Many performance improvements mentioned in the 1.9.X release notes are also available in 2.0.&lt;/li&gt;
  &lt;li&gt;Scanners close server side sessions on close &lt;a href=&quot;https://github.com/apache/accumulo/issues/813&quot;&gt;#813 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/905&quot;&gt;#905 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;upgrading&quot;&gt;Upgrading&lt;/h2&gt;

&lt;p&gt;View the &lt;a href=&quot;/docs/2.x/administration/upgrading&quot;&gt;Upgrading Accumulo documentation&lt;/a&gt; for guidance.&lt;/p&gt;

</description>
        <pubDate>Fri, 02 Aug 2019 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-2.0.0/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-2.0.0/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Using Apache Spark with Accumulo</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; applications can read from and write to Accumulo tables.  To
get started using Spark with Accumulo, checkout the &lt;a href=&quot;/docs/2.x/development/spark&quot;&gt;Spark documentation&lt;/a&gt; in
the 2.0 Accumulo user manual. The &lt;a href=&quot;https://github.com/apache/accumulo-examples/tree/master/spark&quot;&gt;Spark example&lt;/a&gt; application is a good starting point
for using Spark with Accumulo.&lt;/p&gt;

</description>
        <pubDate>Wed, 24 Apr 2019 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2019/04/24/using-spark-with-accumulo.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2019/04/24/using-spark-with-accumulo.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 1.9.3</title>
        <description>&lt;p&gt;Apache Accumulo 1.9.3 contains bug fixes for Write Ahead Logs and compaction.
Users of 1.9.2 are encouraged to upgrade.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/1.9/accumulo_user_manual.html&quot;&gt;User Manual&lt;/a&gt; - In-depth developer and administrator documentation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.9/apidocs/&quot;&gt;Javadocs&lt;/a&gt; - Accumulo 1.9 API&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.9/examples/&quot;&gt;Examples&lt;/a&gt; - Code with corresponding readme files that give step by
step instructions for running example code&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notable-changes&quot;&gt;Notable Changes&lt;/h2&gt;

&lt;h3 id=&quot;multiple-fixes-for-write-ahead-logs&quot;&gt;Multiple Fixes for Write Ahead Logs&lt;/h3&gt;

&lt;p&gt;This release fixes Write Ahead Logs issues that slow or prevent recovery
and in some cases lead to data loss. The fixes reduce the number of WALS
referenced by a tserver, improve error handing, and improve clean up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Eliminates a race condition that could result in data loss during recovery.
If the GC deletes unreferenced WALs from ZK while the master is reading
recovery WALs from ZK, the master may skip WALs it should not, resulting in
data loss.  Fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/866&quot;&gt;#866&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Opening a new WAL in DFS may fail, but still be advertised in ZK. This could
result in a missing WAL during recovery, preventing tablets from loading.
There is no data loss in this case, just WAL references that should not exists.
Reported in &lt;a href=&quot;https://github.com/apache/accumulo/issues/949&quot;&gt;#949&lt;/a&gt; and fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/1057&quot;&gt;#1005&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;tserver failures could result in many empty WALs that unnecessarily slow recovery.
This was fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/845&quot;&gt;#823&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Some write patterns caused tservers to unnecessarily reference a lot of WALs,
which could slow any recovery.  In &lt;a href=&quot;https://github.com/apache/accumulo/issues/860&quot;&gt;#854&lt;/a&gt; the max WALs referenced was
limited regardless of the write pattern, avoiding long recovery times.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;During tablet recovery, filter out logs that do not define the tablet. &lt;a href=&quot;https://github.com/apache/accumulo/issues/881&quot;&gt;#881&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If a tserver fails sorting, a marker file is written to the recovery directory.
This marker prevents any subsequent recovery attempts from succeeding.
Fixed by modifying the WAL RecoveryLogReader to handle failed file markers in &lt;a href=&quot;https://github.com/apache/accumulo/issues/1048&quot;&gt;#961&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Improve performance of serializing mutations to a WAL by avoiding frequent synchronization. &lt;a href=&quot;https://github.com/apache/accumulo/issues/669&quot;&gt;#669&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multiple-fixes-for-compaction-issues&quot;&gt;Multiple Fixes for Compaction Issues&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Stop locking during compaction.  Compactions acquired the tablet lock between each
key value. This created unnecessary contention with other operations like scan and
bulk imports.  The synchronization was removed &lt;a href=&quot;https://github.com/apache/accumulo/issues/1032&quot;&gt;#1031&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Only re-queue compaction when there is activity. &lt;a href=&quot;https://github.com/apache/accumulo/issues/759&quot;&gt;#759&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fix-arrayoutofbounds-error-when-new-files-are-created-affects-all-previous-versions&quot;&gt;Fix ArrayOutOfBounds error when new files are created (affects all previous versions)&lt;/h3&gt;

&lt;p&gt;If the 7 digit base 36 number used to name files attempted to go to 8 digits,
then compactions would fail.  This was fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/562&quot;&gt;#562&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;updated-master-metrics-to-include-fate-metrics&quot;&gt;Updated Master Metrics to include FATE metrics.&lt;/h3&gt;

&lt;p&gt;Added master metrics to provide a snapshot of current FATE operations.  The metrics added:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the number of current FATE transactions in progress,&lt;/li&gt;
  &lt;li&gt;the count of child operations that have occurred on the zookeeper FATE node&lt;/li&gt;
  &lt;li&gt;a count of zookeeper connection errors when the snapshot is taken.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The number of child operations provides a light-weight surrogate for FATE transaction
progression between snapshots. The metrics are controlled with the following properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;master.fate.metrics.enabled - default to &lt;em&gt;false&lt;/em&gt; preserve current metric reporting&lt;/li&gt;
  &lt;li&gt;master.fate.metrics.min.update.interval - default to &lt;em&gt;60s&lt;/em&gt; - there is a hard limit of 10s.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When enabled, the metrics are published to JMX and can optionally be configured using standard
hadoop metrics2 configuration files.&lt;/p&gt;

&lt;h3 id=&quot;fixed-issues-with-native-maps-with-libstdc-82-and-higher&quot;&gt;Fixed issues with Native Maps with libstdc++ 8.2 and higher&lt;/h3&gt;

&lt;p&gt;Versions of libstdc++ 8.2 and higher triggered errors within within the native map code.
This release fixes issues &lt;a href=&quot;https://github.com/apache/accumulo/issues/767&quot;&gt;#767&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/accumulo/issues/769&quot;&gt;#769&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/accumulo/issues/1064&quot;&gt;#1064 &lt;/a&gt;, and &lt;a href=&quot;https://github.com/apache/accumulo/issues/1070&quot;&gt;#1070 &lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;fixed-splitting-tablets-with-files-and-no-data&quot;&gt;Fixed splitting tablets with files and no data&lt;/h3&gt;

&lt;p&gt;The split code assumed that if a tablet had files that it had data in
those files.  There are some edge case where this is not true.  Updated
the split code to handle this &lt;a href=&quot;https://github.com/apache/accumulo/issues/999&quot;&gt;#998&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;log-when-a-scan-waits-a-long-time-for-files&quot;&gt;Log when a scan waits a long time for files.&lt;/h3&gt;

&lt;p&gt;Accumulo has a configurable limit on the max number of files open in a
tserver for all scans.  When too many files are open, scans must wait.
In &lt;a href=&quot;https://github.com/apache/accumulo/issues/978&quot;&gt;#978&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/accumulo/issues/981&quot;&gt;#981&lt;/a&gt; scans that wait too long for files now log a message.&lt;/p&gt;

&lt;h3 id=&quot;fixed-race-condition-in-table-existence-check&quot;&gt;Fixed race condition in table existence check.&lt;/h3&gt;

&lt;p&gt;The Accumulo client code that checks if tables exists had a race
condition.  The race was fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/768&quot;&gt;#768&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/accumulo/issues/973&quot;&gt;#973&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;support-running-mini-accumulo-using-java-11&quot;&gt;Support running Mini Accumulo using Java 11&lt;/h3&gt;

&lt;p&gt;Mini Accumulo made some assumptions about classloaders that were no
longer true in Java 11.  This caused Mini to fail in Java 11.  In
&lt;a href=&quot;https://github.com/apache/accumulo/issues/924&quot;&gt;#924&lt;/a&gt; Mini was updated to work with Java 11, while still working
with Java 7 and 8.&lt;/p&gt;

&lt;h3 id=&quot;fixed-issue-with-improperly-configured-snappy&quot;&gt;Fixed issue with improperly configured Snappy&lt;/h3&gt;

&lt;p&gt;If snappy was configured and the snappy libraries were not available then minor
compactions could hang forever.  In &lt;a href=&quot;https://github.com/apache/accumulo/issues/920&quot;&gt;#920&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/accumulo/issues/925&quot;&gt;#925&lt;/a&gt; this was fixed and minor
compactions will proceed when a different compression is configured.&lt;/p&gt;

&lt;h3 id=&quot;handle-bad-locality-group-config&quot;&gt;Handle bad locality group config.&lt;/h3&gt;

&lt;p&gt;Improperly configured locality groups could cause a tablet to become
inoperative.  This was fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/819&quot;&gt;#819&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/accumulo/issues/840&quot;&gt;#840&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;fixed-bulk-import-race-condition&quot;&gt;Fixed bulk import race condition.&lt;/h3&gt;

&lt;p&gt;There was a race condition in bulk import that could result in files
being imported after a bulk import transaction had completed.  In the
worst case these files were already compacted and garbage collected.
This would cause a tablet to have a reference to a file that did not
exists.  No data would have been lost, but it would cause scans to fail.
The race was fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/800&quot;&gt;#800&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/accumulo/issues/837&quot;&gt;#837&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;fixed-issue-with-hostregextableloadbalancer&quot;&gt;Fixed issue with HostRegexTableLoadBalancer&lt;/h3&gt;

&lt;p&gt;This addresses an issue when using the HostRegexTableLoadBalancer
when the default pool is empty. The load balancer will not assign the tablets at all.
Here, we select a random pool to assign the tablets to. This behavior is on by
default in the HostRegexTableLoadBalancer but can be disabled via
HostRegexTableLoadBalancer configuration setting
 &lt;em&gt;table.custom.balancer.host.regex.HostTableLoadBalancer.ALL&lt;/em&gt;
 Fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/691&quot;&gt;#691&lt;/a&gt; - backported to 1.9 in &lt;a href=&quot;https://github.com/apache/accumulo/issues/710&quot;&gt;#710&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;update-to-libthrift-version&quot;&gt;Update to libthrift version&lt;/h3&gt;

&lt;p&gt;The packaged, binary  tarball contains updated version of libthrift to version 0.9.3-1 to
address thrift CVE. Issue &lt;a href=&quot;https://github.com/apache/accumulo/issues/1029&quot;&gt;#1029&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;useful-links&quot;&gt;Useful links&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://lists.apache.org/thread.html/62a490ee3005ef2ec1f3865f6a9539efc082abc49c90892b49005eed@%3Cdev.accumulo.apache.org%3E&quot;&gt;Release VOTE email thread&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/compare/rel/1.9.2...apache:rel/1.9.3&quot;&gt;All Changes since 1.9.2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues?q=project%3Aapache%2Faccumulo%2F7&quot;&gt;GitHub&lt;/a&gt; - List of issues tracked on GitHub corresponding to this release&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/release/accumulo-1.9.2/&quot;&gt;1.9.2 release notes&lt;/a&gt; - Release notes showing changes in the previous release&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;upgrading&quot;&gt;Upgrading&lt;/h2&gt;

&lt;p&gt;View the &lt;a href=&quot;/docs/2.x/administration/upgrading&quot;&gt;Upgrading Accumulo documentation&lt;/a&gt; for guidance.&lt;/p&gt;

</description>
        <pubDate>Wed, 10 Apr 2019 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-1.9.3/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-1.9.3/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>NoSQL Day 2019</title>
        <description>&lt;p&gt;On May 21st in Washington, DC, there will be a one-day community event for Apache Accumulo,
HBase, and Phoenix called &lt;a href=&quot;https://dataworkssummit.com/nosql-day-2019/&quot;&gt;NoSQL Day&lt;/a&gt;. We hope that these three Apache communities can come together to share
stories from the field and learn from one another. This event is being offered by the
DataWorks Summit organization, prior to their DataWorks Summit event May 20th through 23rd.&lt;/p&gt;

&lt;p&gt;At this time, we are looking for speakers, attendees, and sponsors for the event. For
speakers, we hope to see a wide breadth of subjects and focus, anything from performance,
scaling, real-life applications, dev-ops, or best-practices. All speakers are welcome!
Abstracts can be submitted &lt;a href=&quot;https://dataworkssummit.com/abstracts/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For attendees, we want to get the best and brightest from each of the respective communities
because the organizers believe we have much to learn from from each other. We’ve tried to
keep costs down to make this approachable for all.&lt;/p&gt;

&lt;p&gt;Finally, sponsors are the major enabler to provide events like these at low-costs
to attendees. If you are interested in a corporate sponsorship, please feel free to contact
&lt;a href=&quot;mailto:elserj@apache.org&quot;&gt;Josh Elser&lt;/a&gt; for more information.&lt;/p&gt;

</description>
        <pubDate>Thu, 28 Feb 2019 00:00:00 -0500</pubDate>
        <link>https://accumulo.apache.org/blog/2019/02/28/nosql-day.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2019/02/28/nosql-day.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 2.0.0-alpha-2</title>
        <description>&lt;p&gt;Apache Accumulo 2.0.0-alpha-2 contains numerous changes since the alpha-2. This
alpha release is a preview of features coming in 2.0.0. It is being made
available for preview, testing, and evaluation of those upcoming features, but
is &lt;em&gt;not yet suitable for production use&lt;/em&gt;. API, packaging, and other changes may
still occur before a final 2.0.0 release.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/docs/2.x/&quot;&gt;User Manual&lt;/a&gt; - In-depth developer and administrator documentation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/docs/2.x/apidocs/&quot;&gt;Javadocs&lt;/a&gt; - Accumulo 2.0 API (subject to change)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notable-changes&quot;&gt;Notable Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Please see the &lt;a href=&quot;/release/accumulo-2.0.0&quot;&gt;draft release notes for 2.0.0&lt;/a&gt; for a list of the
changes coming in 2.0.0, many of which are either complete, or nearly
complete in this alpha release.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;since-200-alpha-1&quot;&gt;Since 2.0.0-alpha-1&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;New Map Reduce API &lt;a href=&quot;https://github.com/apache/accumulo/issues/743&quot;&gt;#743 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/751&quot;&gt;#751 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/753&quot;&gt;#753 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/803&quot;&gt;#803 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Deprecated existing map reduce API &lt;a href=&quot;https://github.com/apache/accumulo/commit/2465562cd088b126bfb17523c33c8acd0a48309f&quot;&gt;2465562&lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/804&quot;&gt;#804 &lt;/a&gt;  &lt;a href=&quot;https://github.com/apache/accumulo/issues/892&quot;&gt;#892 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Added ability to create scanners with default auths &lt;a href=&quot;https://github.com/apache/accumulo/issues/744&quot;&gt;#744 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Updated AccumuloClient builder API &lt;a href=&quot;https://github.com/apache/accumulo/issues/792&quot;&gt;#792 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;AccumuloClient was made Closeable &lt;a href=&quot;https://github.com/apache/accumulo/issues/718&quot;&gt;#718 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Scanners close server side sessions on close &lt;a href=&quot;https://github.com/apache/accumulo/issues/813&quot;&gt;#813 &lt;/a&gt; &lt;a href=&quot;https://github.com/apache/accumulo/issues/905&quot;&gt;#905 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 31 Jan 2019 00:00:00 -0500</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-2.0.0-alpha-2/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-2.0.0-alpha-2/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 2.0.0-alpha-1</title>
        <description>&lt;p&gt;Apache Accumulo 2.0.0-alpha-1 contains numerous changes since the 1.9. This
alpha release is a preview of features coming in 2.0.0. It is being made
available for preview, testing, and evaluation of those upcoming features, but
is &lt;em&gt;not yet suitable for production use&lt;/em&gt;. API, packaging, and other changes may
still occur before a final 2.0.0 release.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/docs/2.x/&quot;&gt;User Manual&lt;/a&gt; - In-depth developer and administrator documentation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/docs/2.x/apidocs/&quot;&gt;Javadocs&lt;/a&gt; - Accumulo 2.0 API (subject to change)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notable-changes&quot;&gt;Notable Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Please see the &lt;a href=&quot;/release/accumulo-2.0.0&quot;&gt;draft release notes for 2.0.0&lt;/a&gt; for a list of the
changes coming in 2.0.0, many of which are either complete, or nearly
complete in this alpha release.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 14 Oct 2018 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-2.0.0-alpha-1/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-2.0.0-alpha-1/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Apache Accumulo 1.9.2</title>
        <description>&lt;p&gt;Apache Accumulo 1.9.2 contains fixes for critical write-ahead log bugs.
Users of any previous version of 1.8 or 1.9 are encouraged to upgrade
immediately to avoid those issues.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/1.9/accumulo_user_manual.html&quot;&gt;User Manual&lt;/a&gt; - In-depth developer and administrator documentation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.9/apidocs/&quot;&gt;Javadocs&lt;/a&gt; - Accumulo 1.9 API&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/1.9/examples/&quot;&gt;Examples&lt;/a&gt; - Code with corresponding readme files that give step by
step instructions for running example code&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notable-changes&quot;&gt;Notable Changes&lt;/h2&gt;

&lt;h3 id=&quot;fixes-for-critical-wal-bugs-affects-versions-180-191&quot;&gt;Fixes for Critical WAL Bugs (affects versions 1.8.0-1.9.1)&lt;/h3&gt;

&lt;p&gt;Multiple bugs were fixed in 1.9.2 which affects the behavior of the write-ahead
log mechanism. These vary in significance, ranging from moderate to critical.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/537&quot;&gt;#537&lt;/a&gt; - (Critical) Since 1.8.0, a bug existed which could cause some
write-ahead logs to be removed (garbage collected) before Accumulo was
finished with them. These removed logs could have contained important state
tracking information.  Without the state contained in these logs, some data
in the remaining logs could have been replayed into a table when not needed.
This could have reintroduced deleted data, or introduced duplicate data
(which can interfere with combiners).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/538&quot;&gt;#538&lt;/a&gt; - (Moderate) A bug was introduced in 1.9.1 which resulted in some
false positive IllegalStateExceptions to occur, preventing log recovery.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues/539&quot;&gt;#539&lt;/a&gt; - (Moderate) Since 1.8.0, a race condition existed which could cause a log
file which contains data to be recovered to not be recorded, thus making it
invisible to recovery, if a tserver died within a very small window.  &lt;a href=&quot;https://github.com/apache/accumulo/issues/559&quot;&gt;#559&lt;/a&gt; 
 fixes this issue and may also fix a 1.9.1 deadlock caused by the fix for &lt;a href=&quot;https://github.com/apache/accumulo/issues/441&quot;&gt;#441&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even if you primarily use bulk ingest, Accumulo’s own metadata tables can be
affected by these bugs, causing unexpected behavior after an otherwise routine
and recoverable server failure. As such, these bugs should be a concern to all
users.&lt;/p&gt;

&lt;h3 id=&quot;fixes-for-concurrency-bugs-gathering-table-information-affects-180-191&quot;&gt;Fixes for concurrency bugs gathering table information (affects 1.8.0-1.9.1)&lt;/h3&gt;

&lt;p&gt;Bugs were found with the &lt;code class=&quot;highlighter-rouge&quot;&gt;master.status.threadpool.size&lt;/code&gt; property. If this
property were set to a value other than &lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;, it could cause 100% CPU, hanging,
or &lt;code class=&quot;highlighter-rouge&quot;&gt;ConcurrentModificationException&lt;/code&gt;s.&lt;/p&gt;

&lt;p&gt;These bugs were fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/546&quot;&gt;#546&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;caching-of-file-lengths&quot;&gt;Caching of file lengths&lt;/h3&gt;

&lt;p&gt;RFiles stores metadata at the end of file. When opening a rfile Accumulo
seeks to the end and reads metadata.  To do this seek the file length is needed. 
Before opening a file its length is requested from the namenode.  This can
add more load to a busy namenode.  To alleviate this, a small cache of file lengths was
added in &lt;a href=&quot;https://github.com/apache/accumulo/issues/467&quot;&gt;#467&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;monitor-time-unit-bug&quot;&gt;Monitor time unit bug&lt;/h3&gt;

&lt;p&gt;A bug was found in the monitor which displayed time durations (for example,
those pertaining to bulk imports) in incorrect time units.&lt;/p&gt;

&lt;p&gt;This bug was fixed in &lt;a href=&quot;https://github.com/apache/accumulo/issues/553&quot;&gt;#553&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;other-changes&quot;&gt;Other Changes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/accumulo/issues?q=project%3Aapache%2Faccumulo%2F6&quot;&gt;GitHub&lt;/a&gt; - List of issues tracked on GitHub corresponding to this release&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/release/accumulo-1.9.1/&quot;&gt;1.9.1 release notes&lt;/a&gt; - Release notes showing changes in the previous release&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;upgrading&quot;&gt;Upgrading&lt;/h2&gt;

&lt;p&gt;View the &lt;a href=&quot;/docs/2.x/administration/upgrading&quot;&gt;Upgrading Accumulo documentation&lt;/a&gt; for guidance.&lt;/p&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;All ITs passed with Hadoop 3.0.0 (hadoop.profile=3)&lt;/li&gt;
  &lt;li&gt;All ITs passed with Hadoop 2.6.4 (hadoop.profile=2)&lt;/li&gt;
  &lt;li&gt;Ran 3 continuous ingesters successfully for 24 hours on a 10 node cluster
with agitation and pausing. Verification for all 3 tests was successful.&lt;/li&gt;
  &lt;li&gt;Ran continuous ingest for 24 hours and verified without agitation on a 10
node cluster.&lt;/li&gt;
  &lt;li&gt;Tested &lt;a href=&quot;https://fluo.apache.org&quot;&gt;Apache Fluo&lt;/a&gt; build and ITs passed against this version.&lt;/li&gt;
  &lt;li&gt;Ran a single-node cluster with &lt;a href=&quot;https://github.com/apache/fluo-uno&quot;&gt;Uno&lt;/a&gt; and created a table, ingested data,
flushed, compacted, scanned, and deleted the table.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 19 Jul 2018 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/release/accumulo-1.9.2/</link>
        <guid isPermaLink="true">https://accumulo.apache.org/release/accumulo-1.9.2/</guid>
        
        
        <category>release</category>
        
      </item>
    
      <item>
        <title>Accumulo Summit is on October 15th!</title>
        <description>&lt;p&gt;The &lt;a href=&quot;http://accumulosummit.com/&quot;&gt;Fifth Annual Accumulo Summit&lt;/a&gt; will be held on October 15, 2018 at the &lt;a href=&quot;http://accumulosummit.com/about/venue/&quot;&gt;Sheraton Columbia Town Center Hotel&lt;/a&gt; in Columbia, MD.&lt;/p&gt;

&lt;p&gt;This day-long event offers a unique opportunity for attendees to get introduced to Apache Accumulo, sharpen their skillsets, and connect with leading Accumulo users and developers.&lt;/p&gt;

&lt;p&gt;Have a great idea you’d like to share?  Engineers, architects, and business leaders are encouraged to share their experiences or present a topic that would be of interest to the Accumulo community.  &lt;a href=&quot;http://accumulosummit.com/program/submit-talk/&quot;&gt;Talks can be submitted &lt;/a&gt; through August 1st.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://accumulosummit.com/register/&quot;&gt;Early bird registration is now open&lt;/a&gt;!  Sign up before September 1st to save $50 off the regular admission price.&lt;/p&gt;

</description>
        <pubDate>Thu, 05 Jul 2018 00:00:00 -0400</pubDate>
        <link>https://accumulo.apache.org/blog/2018/07/05/accumulo-summit.html</link>
        <guid isPermaLink="true">https://accumulo.apache.org/blog/2018/07/05/accumulo-summit.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
